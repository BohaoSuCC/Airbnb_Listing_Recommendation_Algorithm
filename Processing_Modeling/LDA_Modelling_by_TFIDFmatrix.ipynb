{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "import unicodedata\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "import contextily as ctx\n",
    "import urllib.request\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder  # We don't use this but I point out where you *could*\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import ngrams, FreqDist\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.matutils import corpus2dense\n",
    "from gensim.models import tfidfmodel\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopword_list = set(stopwords.words('english'))\n",
    "\n",
    "# Import everthing from textual/__init__.py\n",
    "# Including bunch of tools and functions we could use for NLP \n",
    "from textual import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Latent Dirchlet Allocation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用TF-IDF模型进行向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and Transform\n",
    "tfvectorizer = TfidfVectorizer(use_idf=True, ngram_range=(1,4), \n",
    "                               max_df=0.3, min_df=0.005,stop_words='english') # modify these parameter to improve the model\n",
    "tfidf_corpus = tfvectorizer.fit_transform(corpus) # TF-transformed corpus\n",
    "\n",
    "# Transformed corpus\n",
    "# 将整个TF-IDF转换后的语料库转换为DataFrame格式 \n",
    "tfidf_dataframe = pd.DataFrame(data=tfidf_corpus.toarray(),\n",
    "                        columns=tfvectorizer.get_feature_names_out())#将稀疏矩阵转换为密集矩阵，并使用相同的特征名称作为列名。\n",
    "print(f\"TF/IDF data frame has {tfidf_dataframe.shape[0]:,} rows and {tfidf_dataframe.shape[1]:,} columns.\")#打印DataFrame的行数和列数，即文档数和特征数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建和训练LDA模型\n",
    "\n",
    "接着，构建LDA模型并用预处理后的数据进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定n_components参数\n",
    "\n",
    "\n",
    "# 准备Gensim所需的数据结构\n",
    "texts = [doc.split() for doc in corpus]                 #分词\n",
    "dictionary = Dictionary(texts)                          #每个词创建唯一值字典\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "#将其转换为TFIDF模型\n",
    "tfidf_model = TfidfModel(bow_corpus)\n",
    "tfidf_corpus = [tfidf_model[doc] for doc in bow_corpus]\n",
    "\n",
    "\"\"\"\n",
    "# 您需要将Gensim的TF-IDF语料库转换为scikit-learn可以处理的格式。\n",
    "# 通常，这涉及到将Gensim生成的稀疏表示转换为一个密集的NumPy数组或者一个稀疏矩阵。\n",
    "num_terms = len(dictionary)\n",
    "num_docs = len(tfidf_corpus)\n",
    "tfidf_sparse = corpus2dense(tfidf_corpus,num_docs=num_docs,num_terms=num_terms).T\n",
    "\"\"\"\n",
    "\n",
    "# 测试不同的主题数\n",
    "coherence_values = []\n",
    "\n",
    "for n_topics in range(1, 41):\n",
    "    LDA = LdaModel(corpus=tfidf_corpus, id2word=dictionary, num_topics=n_topics, random_state=42,iterations=800)\n",
    "    CM = CoherenceModel(model=LDA, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_values.append(CM.get_coherence())\n",
    "\n",
    "\n",
    "# 选择最佳主题数\n",
    "optimal_topics = np.argmax(coherence_values) + 1  # 加1因为索引从0开始\n",
    "print(f\"Optimal number of topics: {optimal_topics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存不同主题的coherence值，\n",
    "# coherence得分一般在0-1之间，\n",
    "# 一般超过0.5被认为模型拟合较好\n",
    "\n",
    "\n",
    "# 创建包含主题数和一致性得分的DataFrame\n",
    "LDA_topic_coherence_data = {'Topic_Num': range(1, len(coherence_values) + 1), 'Coherence_Score': coherence_values}\n",
    "LDA_topic_coherence_frame = pd.DataFrame(LDA_topic_coherence_data)\n",
    "# 保存为CSV文件\n",
    "LDA_topic_coherence_frame.to_csv(\"./Data/coherence_values.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将主题分配给文档\n",
    "\n",
    "对每个文档（房源描述）分配一个主题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置LDA模型\n",
    "LDA = LdaModel(corpus=tfidf_corpus, id2word=dictionary, num_topics=LDA_topic_coherence_frame.loc[LDA_topic_coherence_frame['Coherence_Score'].idxmax(),'Topic_Num'], random_state=42,iterations=800)\n",
    "# 对每个文档获取主题分布\n",
    "doc_topics = [LDA.get_document_topics(bow) for bow in tfidf_corpus]\n",
    "\n",
    "# 获取每个主题的主要词汇\n",
    "topics = LDA.print_topics(num_words=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看主题和关键词\n",
    "\n",
    "查看模型找出的主题和每个主题的关键词。并且保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取每个主题的主题词及其权重\n",
    "topics = LDA.show_topics(num_topics=16, num_words=20, formatted=False)\n",
    "\n",
    "# 创建一个list保存每个主题的主题词及权重\n",
    "LDA_topics_data = []\n",
    "\n",
    "for topic_num, topic_words in topics:\n",
    "    for word, weight in topic_words:\n",
    "        LDA_topics_data.append({'Topic': topic_num, 'Word': word, 'Weight': weight})\n",
    "\n",
    "# 转换为DataFrame\n",
    "LDA_topics_frame = pd.DataFrame(LDA_topics_data)\n",
    "\n",
    "# 保存这个模型生成的主题结果\n",
    "LDA_topics_frame.to_csv(os.path.join(\"Data\",\"lda_topics_and_words.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将doc_topic转换为dataframe，每个文档（listing）的主题分布及其占比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_lda_topic = pd.DataFrame(doc_topics)\n",
    "#循环遍历每一行\n",
    "for i in range(len(listing_lda_topic)):\n",
    "    temp_list = listing_lda_topic.iloc[i].dropna()\n",
    "    # 创建一个全为0的序列，用于替换当前行\n",
    "    zero_series = pd.Series([0.0] * len(listing_lda_topic.columns), index=listing_lda_topic.columns)\n",
    "    listing_lda_topic.iloc[i] = zero_series\n",
    "    for j in temp_list.index:\n",
    "        # 从原始序列中获取列名和值\n",
    "        col = temp_list[j][0] if isinstance(temp_list[j], (list, tuple)) else j\n",
    "        value = temp_list[j][1] if isinstance(temp_list[j], (list, tuple)) else temp_list[j]\n",
    "        # 更新DataFrame\n",
    "        listing_lda_topic.at[i, col] = value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存lda模型后每个房源的主题分布及占比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_lda_topic.to_csv(os.path.join(\"Data\",\"listing_lda_topic.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
