{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SBH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "import unicodedata\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import contextily as ctx\n",
    "import urllib.request\n",
    "import ast  # 用于安全地将字符串转换为列表\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder  # We don't use this but I point out where you *could*\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import ngrams, FreqDist\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.matutils import corpus2dense\n",
    "from gensim.models import tfidfmodel\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopword_list = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airbnb_Listing = pd.read_csv(os.path.join(\"..\",\"Data\",\"Airbnb_Listing_norm.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    . heating  standard cable  wifi  smoke alarm  ...\n",
       "1    . window guard  bathtub  water kettle  laundro...\n",
       "2    . bathtub  water kettle  laundromat nearby  pr...\n",
       "3    . shampoo  luggage dropoff allow  dryer  micro...\n",
       "4    . window guard  bathtub  water kettle  laundro...\n",
       "5    . single level home  bathtub  water kettle  la...\n",
       "6    . bathtub  water kettle  laundromat nearby  pa...\n",
       "7    . bathtub  free dryer . unit  water kettle  la...\n",
       "8    . shampoo  luggage dropoff allow  microwave  c...\n",
       "9    . heating  hair dryer  iron  washer  lock bedr...\n",
       "Name: amenities_norm, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Airbnb_Listing['amenities_norm'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_word2vec = Airbnb_Listing['amenities_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SBH\\AppData\\Local\\Temp\\ipykernel_29052\\795702335.py:2: DtypeWarning: Columns (163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  amenities_norm_split = pd.read_csv(os.path.join(\"..\",\"Data\",\"amenities_norm_split.csv\"))\n"
     ]
    }
   ],
   "source": [
    "# 从norm并且split后的数据读取csv\n",
    "amenities_norm_split = pd.read_csv(os.path.join(\"..\",\"Data\",\"amenities_norm_split.csv\"))\n",
    "\n",
    "# 将 'amenities' 列中的字符串转换为列表\n",
    "# 使用 ast.literal_eval 安全地评估字符串表达的列表\n",
    "amenities_ast_literal = amenities_norm_split\n",
    "\n",
    "# 准备用于 Word2Vec 的数据\n",
    "\n",
    "\n",
    "# 指定训练参数\n",
    "dims = 400\n",
    "window = 10\n",
    "\n",
    "# 训练 Word2Vec 模型\n",
    "model = Word2Vec(sentences=amenities_ast_literal, vector_size=dims, window=window, min_count=3, workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存word2vec模型\n",
    "model.save(os.path.join(\"..\",\"Model\",f\"word2vec-d{dims}-w{window}.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SBH\\AppData\\Local\\Temp\\ipykernel_29052\\1319324662.py:1: DtypeWarning: Columns (68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  Airbnb_Listing_origin = pd.read_csv(os.path.join(\"..\",\"Data\",\"Data_InsideAirbnb\",\"listings.csv.gz\"))\n"
     ]
    }
   ],
   "source": [
    "Airbnb_Listing_origin = pd.read_csv(os.path.join(\"..\",\"Data\",\"Data_InsideAirbnb\",\"listings.csv.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算所有listing的average incom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7194.986408705343"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每个listing的收入与average收入相比\n",
    "if Airbnb_Listing_origin['price'].dtype == 'object':\n",
    "    Airbnb_Listing_origin['price'] = Airbnb_Listing_origin['price'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "Airbnb_Listing['sum_income'] = Airbnb_Listing_origin['minimum_nights']*2.7*Airbnb_Listing_origin['number_of_reviews_ltm']*Airbnb_Listing_origin['price']\n",
    "\n",
    "average_income_forlisting = Airbnb_Listing['sum_income'].mean()\n",
    "average_income_forlisting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airbnb_Listing['profitable'] = (Airbnb_Listing['sum_income'] >= average_income_forlisting).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_norm_split_doc = amenities_norm_split.apply(lambda row: row.tolist(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换文本向量\n",
    "def document_vector(word2vec_model, doc):\n",
    "    # 移除不在词汇表中的词\n",
    "    doc = [word for word in doc if word in word2vec_model.wv.key_to_index]\n",
    "    # 处理空文档的情况\n",
    "    if len(doc) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    # 计算均值向量\n",
    "    return np.mean(word2vec_model.wv[doc], axis=0)\n",
    "\n",
    "# 为每个文档计算向量\n",
    "doc_vectors = np.array([document_vector(model, doc) for doc in amenities_norm_split_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分词处理：您使用的是 text.split(\" \") 来分词。这意味着您假设文本中的每个单词之间由两个空格分隔。请确保这与您的数据格式一致。如果是普通英文文本，通常单词之间只有一个空格，那么应该使用 text.split()。\n",
    "\n",
    "空文档处理：在 document_vector 函数中，如果文档中所有的词都不在模型的词汇表中，那么 word2vec_model.wv[doc] 将是一个空列表，这会导致 np.mean 报错。您需要处理这种情况。\n",
    "\n",
    "文档向量计算：当您计算文档向量时，您使用的是 np.array([document_vector(model, doc) for doc in texts])。这里 texts 应该是分词后的文本数据。请确保 texts 和 texts_word2vec 是一致的，即 texts 应该是用于训练 Word2Vec 模型的相同数据。\n",
    "\n",
    "标签和特征数据：确保 labels 是与 doc_vectors 对应的目标变量数组。labels 应该有与 doc_vectors 相同数量的元素。\n",
    "\n",
    "模型性能评估：在最后，您计算了准确率，这是评估分类模型性能的一个常用指标。根据您的应用情况，可能还需要考虑其他指标，如精确率、召回率和F1分数。\n",
    "\n",
    "异常和错误处理：在实际应用中，建议添加异常处理和错误检查，确保代码的健壮性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8054007959067652\n"
     ]
    }
   ],
   "source": [
    "# 随机森林方法\n",
    "\n",
    "#使用任何类型的分类器来预测是否income超过平均值\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc_vectors, Airbnb_Listing['profitable'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 训练分类器\n",
    "classifier = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7956793632745879\n"
     ]
    }
   ],
   "source": [
    "#SVM方法\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc_vectors, Airbnb_Listing['profitable'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建 SVM 分类器实例\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# 训练分类器\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置要测试的参数\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100], \n",
    "    'gamma': ['scale', 'auto'], \n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# 创建带有参数网格的 GridSearchCV 对象\n",
    "grid_search = GridSearchCV(SVC(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# 训练网格搜索模型\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 找到最优参数\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# 使用最优参数的模型对测试集进行预测\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存SVM模型与保存后的Airbnb_Listing_norm_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_classfier_model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(classifier, 'randforest_classfier_model.joblib')\n",
    "dump(svm_classifier, 'svm_classfier_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
