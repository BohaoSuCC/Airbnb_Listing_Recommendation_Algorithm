{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SBH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "import unicodedata\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import contextily as ctx\n",
    "import urllib.request\n",
    "import ast  # 用于安全地将字符串转换为列表\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder  # We don't use this but I point out where you *could*\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import ngrams, FreqDist\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.matutils import corpus2dense\n",
    "from gensim.models import tfidfmodel\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopword_list = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airbnb_Listing = pd.read_csv(os.path.join(\"..\",\"Data\",\"Airbnb_Listing_norm.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    . heating  standard cable  wifi  smoke alarm  ...\n",
       "1    . window guard  bathtub  water kettle  laundro...\n",
       "2    . bathtub  water kettle  laundromat nearby  pr...\n",
       "3    . shampoo  luggage dropoff allow  dryer  micro...\n",
       "4    . window guard  bathtub  water kettle  laundro...\n",
       "5    . single level home  bathtub  water kettle  la...\n",
       "6    . bathtub  water kettle  laundromat nearby  pa...\n",
       "7    . bathtub  free dryer . unit  water kettle  la...\n",
       "8    . shampoo  luggage dropoff allow  microwave  c...\n",
       "9    . heating  hair dryer  iron  washer  lock bedr...\n",
       "Name: amenities_norm, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Airbnb_Listing['amenities_norm'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_word2vec = Airbnb_Listing['amenities_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SBH\\AppData\\Local\\Temp\\ipykernel_18728\\3000927334.py:2: DtypeWarning: Columns (163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  amenities_norm_split = pd.read_csv(os.path.join(\"..\",\"Data\",\"amenities_norm_split.csv\"))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heating</td>\n",
       "      <td>standard</td>\n",
       "      <td>cable</td>\n",
       "      <td>wifi</td>\n",
       "      <td>smoke</td>\n",
       "      <td>alarm</td>\n",
       "      <td>dryer</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>washer</td>\n",
       "      <td>essentials</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>window</td>\n",
       "      <td>guard</td>\n",
       "      <td>bathtub</td>\n",
       "      <td>water</td>\n",
       "      <td>kettle</td>\n",
       "      <td>laundromat</td>\n",
       "      <td>nearby</td>\n",
       "      <td>indoor</td>\n",
       "      <td>fireplace</td>\n",
       "      <td>microwave</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bathtub</td>\n",
       "      <td>water</td>\n",
       "      <td>kettle</td>\n",
       "      <td>laundromat</td>\n",
       "      <td>nearby</td>\n",
       "      <td>private</td>\n",
       "      <td>patio</td>\n",
       "      <td>balcony</td>\n",
       "      <td>paid</td>\n",
       "      <td>street</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shampoo</td>\n",
       "      <td>luggage</td>\n",
       "      <td>dropoff</td>\n",
       "      <td>allow</td>\n",
       "      <td>dryer</td>\n",
       "      <td>microwave</td>\n",
       "      <td>coffee</td>\n",
       "      <td>maker</td>\n",
       "      <td>water</td>\n",
       "      <td>iron</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>window</td>\n",
       "      <td>guard</td>\n",
       "      <td>bathtub</td>\n",
       "      <td>water</td>\n",
       "      <td>kettle</td>\n",
       "      <td>laundromat</td>\n",
       "      <td>nearby</td>\n",
       "      <td>free</td>\n",
       "      <td>driveway</td>\n",
       "      <td>park</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87941</th>\n",
       "      <td>water</td>\n",
       "      <td>kettle</td>\n",
       "      <td>laundromat</td>\n",
       "      <td>nearby</td>\n",
       "      <td>shampoo</td>\n",
       "      <td>luggage</td>\n",
       "      <td>dropoff</td>\n",
       "      <td>allow</td>\n",
       "      <td>dryer</td>\n",
       "      <td>coffee</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87942</th>\n",
       "      <td>bathtub</td>\n",
       "      <td>free</td>\n",
       "      <td>dryer</td>\n",
       "      <td>unit</td>\n",
       "      <td>water</td>\n",
       "      <td>kettle</td>\n",
       "      <td>private</td>\n",
       "      <td>patio</td>\n",
       "      <td>balcony</td>\n",
       "      <td>fire</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87943</th>\n",
       "      <td>window</td>\n",
       "      <td>guard</td>\n",
       "      <td>bathtub</td>\n",
       "      <td>water</td>\n",
       "      <td>kettle</td>\n",
       "      <td>laundromat</td>\n",
       "      <td>nearby</td>\n",
       "      <td>paid</td>\n",
       "      <td>street</td>\n",
       "      <td>park</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87944</th>\n",
       "      <td>water</td>\n",
       "      <td>kettle</td>\n",
       "      <td>dryer</td>\n",
       "      <td>microwave</td>\n",
       "      <td>coffee</td>\n",
       "      <td>maker</td>\n",
       "      <td>linens</td>\n",
       "      <td>iron</td>\n",
       "      <td>patio</td>\n",
       "      <td>balcony</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87945</th>\n",
       "      <td>bathtub</td>\n",
       "      <td>free</td>\n",
       "      <td>dryer</td>\n",
       "      <td>unit</td>\n",
       "      <td>water</td>\n",
       "      <td>kettle</td>\n",
       "      <td>shampoo</td>\n",
       "      <td>free</td>\n",
       "      <td>washer</td>\n",
       "      <td>unit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87946 rows × 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1           2           3        4           5  \\\n",
       "0      heating  standard       cable        wifi    smoke       alarm   \n",
       "1       window     guard     bathtub       water   kettle  laundromat   \n",
       "2      bathtub     water      kettle  laundromat   nearby     private   \n",
       "3      shampoo   luggage     dropoff       allow    dryer   microwave   \n",
       "4       window     guard     bathtub       water   kettle  laundromat   \n",
       "...        ...       ...         ...         ...      ...         ...   \n",
       "87941    water    kettle  laundromat      nearby  shampoo     luggage   \n",
       "87942  bathtub      free       dryer        unit    water      kettle   \n",
       "87943   window     guard     bathtub       water   kettle  laundromat   \n",
       "87944    water    kettle       dryer   microwave   coffee       maker   \n",
       "87945  bathtub      free       dryer        unit    water      kettle   \n",
       "\n",
       "             6        7          8           9  ...  208  209  210  211  212  \\\n",
       "0        dryer  kitchen     washer  essentials  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "1       nearby   indoor  fireplace   microwave  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "2        patio  balcony       paid      street  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "3       coffee    maker      water        iron  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "4       nearby     free   driveway        park  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "...        ...      ...        ...         ...  ...  ...  ...  ...  ...  ...   \n",
       "87941  dropoff    allow      dryer      coffee  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "87942  private    patio    balcony        fire  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "87943   nearby     paid     street        park  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "87944   linens     iron      patio     balcony  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "87945  shampoo     free     washer        unit  ...  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       213  214  215  216  217  \n",
       "0      NaN  NaN  NaN  NaN  NaN  \n",
       "1      NaN  NaN  NaN  NaN  NaN  \n",
       "2      NaN  NaN  NaN  NaN  NaN  \n",
       "3      NaN  NaN  NaN  NaN  NaN  \n",
       "4      NaN  NaN  NaN  NaN  NaN  \n",
       "...    ...  ...  ...  ...  ...  \n",
       "87941  NaN  NaN  NaN  NaN  NaN  \n",
       "87942  NaN  NaN  NaN  NaN  NaN  \n",
       "87943  NaN  NaN  NaN  NaN  NaN  \n",
       "87944  NaN  NaN  NaN  NaN  NaN  \n",
       "87945  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[87946 rows x 218 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从norm并且split后的数据读取csv\n",
    "amenities_norm_split = pd.read_csv(os.path.join(\"..\",\"Data\",\"amenities_norm_split.csv\"))\n",
    "\n",
    "# 将 'amenities' 列中的字符串转换为列表\n",
    "# 使用 ast.literal_eval 安全地评估字符串表达的列表\n",
    "amenities_ast_literal = amenities_norm_split\n",
    "amenities_ast_literal.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = amenities_ast_literal.apply(lambda row: [item for item in row if item is not None], axis=1).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87946\n"
     ]
    }
   ],
   "source": [
    "print(len(list_of_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 准备用于 Word2Vec 的数据\n",
    "\n",
    "\n",
    "# 指定训练参数\n",
    "dims = 500\n",
    "window = 20\n",
    "\n",
    "# 训练 Word2Vec 模型\n",
    "model = Word2Vec(sentences=list_of_lists, vector_size=dims, window=window, min_count=3, workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存word2vec模型\n",
    "model.save(os.path.join(\"..\",\"Model\",f\"word2vec-d{dims}-w{window}.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SBH\\AppData\\Local\\Temp\\ipykernel_18728\\1319324662.py:1: DtypeWarning: Columns (68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  Airbnb_Listing_origin = pd.read_csv(os.path.join(\"..\",\"Data\",\"Data_InsideAirbnb\",\"listings.csv.gz\"))\n"
     ]
    }
   ],
   "source": [
    "Airbnb_Listing_origin = pd.read_csv(os.path.join(\"..\",\"Data\",\"Data_InsideAirbnb\",\"listings.csv.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算所有listing的average incom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7194.986408705343"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每个listing的收入与average收入相比\n",
    "if Airbnb_Listing_origin['price'].dtype == 'object':\n",
    "    Airbnb_Listing_origin['price'] = Airbnb_Listing_origin['price'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "Airbnb_Listing['sum_income'] = Airbnb_Listing_origin['minimum_nights']*2.7*Airbnb_Listing_origin['number_of_reviews_ltm']*Airbnb_Listing_origin['price']\n",
    "\n",
    "average_income_forlisting = Airbnb_Listing['sum_income'].mean()\n",
    "average_income_forlisting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airbnb_Listing['profitable'] = (Airbnb_Listing['sum_income'] >= average_income_forlisting).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_norm_split_doc = amenities_norm_split.apply(lambda row: row.tolist(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换文本向量\n",
    "def document_vector(word2vec_model, doc):\n",
    "    # 移除不在词汇表中的词\n",
    "    doc = [word for word in doc if word in word2vec_model.wv.key_to_index]\n",
    "    # 处理空文档的情况\n",
    "    if len(doc) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    # 计算均值向量\n",
    "    return np.mean(word2vec_model.wv[doc], axis=0)\n",
    "\n",
    "# 为每个文档计算向量\n",
    "doc_vectors = np.array([document_vector(model, doc) for doc in amenities_norm_split_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分词处理：您使用的是 text.split(\" \") 来分词。这意味着您假设文本中的每个单词之间由两个空格分隔。请确保这与您的数据格式一致。如果是普通英文文本，通常单词之间只有一个空格，那么应该使用 text.split()。\n",
    "\n",
    "空文档处理：在 document_vector 函数中，如果文档中所有的词都不在模型的词汇表中，那么 word2vec_model.wv[doc] 将是一个空列表，这会导致 np.mean 报错。您需要处理这种情况。\n",
    "\n",
    "文档向量计算：当您计算文档向量时，您使用的是 np.array([document_vector(model, doc) for doc in texts])。这里 texts 应该是分词后的文本数据。请确保 texts 和 texts_word2vec 是一致的，即 texts 应该是用于训练 Word2Vec 模型的相同数据。\n",
    "\n",
    "标签和特征数据：确保 labels 是与 doc_vectors 对应的目标变量数组。labels 应该有与 doc_vectors 相同数量的元素。\n",
    "\n",
    "模型性能评估：在最后，您计算了准确率，这是评估分类模型性能的一个常用指标。根据您的应用情况，可能还需要考虑其他指标，如精确率、召回率和F1分数。\n",
    "\n",
    "异常和错误处理：在实际应用中，建议添加异常处理和错误检查，确保代码的健壮性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8054007959067652\n"
     ]
    }
   ],
   "source": [
    "# 随机森林方法\n",
    "\n",
    "#使用任何类型的分类器来预测是否income超过平均值\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc_vectors, Airbnb_Listing['profitable'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 训练分类器\n",
    "classifier = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7957362137578169\n"
     ]
    }
   ],
   "source": [
    "#SVM方法\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc_vectors, Airbnb_Listing['profitable'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建 SVM 分类器实例\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# 训练分类器\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置要测试的参数\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100], \n",
    "    'gamma': ['scale', 'auto'], \n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# 创建带有参数网格的 GridSearchCV 对象\n",
    "grid_search = GridSearchCV(SVC(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# 训练网格搜索模型\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 找到最优参数\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# 使用最优参数的模型对测试集进行预测\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存SVM模型与保存后的Airbnb_Listing_norm_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_classfier_model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(classifier, 'randforest_classfier_model.joblib')\n",
    "dump(svm_classifier, 'svm_classfier_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "词向量可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec.load(os.path.join(\"Model\",\"word2vec-d400-w10.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_norm_split = Airbnb_Listing['amenities_norm']\n",
    "amenities_norm_split = list(amenities_norm_split)\n",
    "amenities_norm_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_tokenize(list_of_strings):\n",
    "    processed_lists = []\n",
    "    for string in list_of_strings:\n",
    "        # 删除所有的 '.' 符号\n",
    "        string = string.replace('.', '')\n",
    "        # 替换所有连续的两个空格为一个空格\n",
    "        string = string.replace('  ', ' ')\n",
    "        # 分词\n",
    "        tokens = string.split()\n",
    "        # 将处理后的列表添加到结果中\n",
    "        processed_lists.append(tokens)\n",
    "    return processed_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_norm_split = preprocess_and_tokenize(amenities_norm_split)\n",
    "\n",
    "amenities_norm_split = pd.DataFrame(amenities_norm_split)\n",
    "\n",
    "amenities_norm_split.to_csv(os.path.join(\"Data\",\"amenities_norm_split.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将训练后model应用于'amenities'列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"# 预处理函数\n",
    "def preprocess(text):\n",
    "    # 这里添加文本清洗逻辑（例如：转换为小写，去除标点等）\n",
    "    return text.lower()\"\"\"\n",
    "\n",
    "# 向量化函数\n",
    "def vectorize(text, model):\n",
    "    # 将文本分解为单词，并过滤掉模型词汇表中不存在的单词\n",
    "    words = [word for word in text if word in model.wv.key_to_index]\n",
    "    # 如果文本中没有模型已知的单词，则返回零向量\n",
    "    if len(words) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    # 计算所有单词向量的平均值\n",
    "    word_vectors = [model.wv[word] for word in words]\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
