{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "bibliography: bio.bib\n",
        "csl: harvard-cite-them-right.csl\n",
        "title: DeskB's Group Project\n",
        "execute:\n",
        "  echo: false\n",
        "format:\n",
        "  html:\n",
        "    theme:\n",
        "      - minty\n",
        "      - css/web.scss\n",
        "    code-copy: true\n",
        "    code-link: true\n",
        "    toc: true\n",
        "    toc-title: On this page\n",
        "    toc-depth: 2\n",
        "    toc_float:\n",
        "      collapsed: false\n",
        "      smooth_scroll: true\n",
        "  pdf:\n",
        "    include-in-header:\n",
        "      text: |\n",
        "        \\addtokomafont{disposition}{\\rmfamily}\n",
        "    mainfont: Spectral\n",
        "    sansfont: Roboto\n",
        "    monofont: JetBrainsMono-Regular\n",
        "    papersize: a4\n",
        "    geometry:\n",
        "      - top=25mm\n",
        "      - left=40mm\n",
        "      - right=30mm\n",
        "      - bottom=25mm\n",
        "      - heightrounded\n",
        "    toc: false\n",
        "    number-sections: false\n",
        "    colorlinks: true\n",
        "    highlight-style: github\n",
        "---"
      ],
      "id": "e0d78d4d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Declaration of Authorship {.unnumbered .unlisted}\n",
        "\n",
        "We, \\[DeskB\\], confirm that the work presented in this assessment is our own. Where information has been derived from other sources, we confirm that this has been indicated in the work. Where a Large Language Model such as ChatGPT has been used we confirm that we have made its contribution to the final submission clear.\n",
        "\n",
        "Date: 11th December 2023\n",
        "\n",
        "Student Numbers: 20017359 23032922 23081403 23103585 23130397\n",
        "\n",
        "## Brief Group Reflection\n",
        "\n",
        "| What Went Well | What Was Challenging |\n",
        "|----------------|----------------------|\n",
        "| A              | B                    |\n",
        "| C              | D                    |\n",
        "\n",
        "## Priorities for Feedback\n",
        "\n",
        "Are there any areas on which you would appreciate more detailed feedback if we're able to offer it?\n",
        "\n",
        "\n",
        "\n",
        "```{=html}\n",
        "<style type=\"text/css\">\n",
        ".duedate {\n",
        "  border: dotted 2px red; \n",
        "  background-color: rgb(255, 235, 235);\n",
        "  height: 50px;\n",
        "  line-height: 50px;\n",
        "  margin-left: 40px;\n",
        "  margin-right: 40px\n",
        "  margin-top: 10px;\n",
        "  margin-bottom: 10px;\n",
        "  color: rgb(150,100,100);\n",
        "  text-align: center;\n",
        "}\n",
        "</style>\n",
        "```\n",
        "\n",
        "{{< pagebreak >}}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Response to Questions\n"
      ],
      "id": "1d1c23dc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import re\n",
        "import math\n",
        "import string\n",
        "import unicodedata\n",
        "import gensim\n",
        "import matplotlib as mpl\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import nltk\n",
        "import seaborn as sns\n",
        "import ast  # 用于安全地将字符串转换为列表\n",
        "import umap\n",
        "\n",
        "import contextily as ctx\n",
        "import urllib.request\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "from scipy.spatial import cKDTree\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.ndimage import convolve\n",
        "from shapely.geometry import Point\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder  # We don't use this but I point out where you *could*\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.manifold import TSNE\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk import ngrams, FreqDist\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.matutils import Sparse2Corpus\n",
        "from gensim.matutils import corpus2dense\n",
        "from gensim.models import tfidfmodel\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import TfidfModel\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "\n",
        "from joblib import dump\n",
        "from joblib import load\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# Import everthing from textual/__init__.py\n",
        "# Including bunch of tools and functions we could use for NLP \n",
        "from textual import *"
      ],
      "id": "9e1788e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Download and read the csv file remotely from url\n",
        "host = 'http://data.insideairbnb.com'\n",
        "path = 'united-kingdom/england/london/2023-09-06/data'\n",
        "file = 'listings.csv.gz'\n",
        "url  = f'{host}/{path}/{file}'\n",
        "\n",
        "# Save csv file\n",
        "if os.path.exists(file):\n",
        "  Airbnb_Listing = pd.read_csv(file, compression='gzip', low_memory=False)\n",
        "else: \n",
        "  Airbnb_Listing = pd.read_csv(url, compression='gzip', low_memory=False)\n",
        "  Airbnb_Listing.to_csv(file)\n",
        "\n",
        "# Download and read the gpkg file remotel from url\n",
        "host = 'https://data.london.gov.uk'\n",
        "path = 'download/london_boroughs/9502cdec-5df0-46e3-8aa1-2b5c5233a31f'\n",
        "file = 'London_Boroughs.gpkg'\n",
        "url  = f'{host}/{path}/{file}'\n",
        "\n",
        "# Save gkpg file\n",
        "if os.path.exists(file):\n",
        "  London_boroughs = gpd.read_file(file, compression='gzip', low_memory=False)\n",
        "else: \n",
        "  London_boroughs = gpd.read_file(url, compression='gzip', low_memory=False)\n",
        "  London_boroughs.to_file(file, driver='GPKG')"
      ],
      "id": "1e181d9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Who collected the data? ( 2 points; Answer due Week 7 )\n",
        "\n",
        "::: 1.[\\*listings.csv](http://data.insideairbnb.com/united-kingdom/england/london/2023-09-06/data/listings.csv.gz) : This dataset was created by automatically scraping public information from Airbnb's Website. Murray Cox was one of the main founder and technicians of this mission driven project that aims to provide data and advocacy about Airbnb's impact on residential communities. [\\[1\\]]((http://insideairbnb.com/about))\n",
        "\n",
        "2.[\\*London_Boroughs.gpkg](https://data.london.gov.uk/download/london_boroughs/9502cdec-5df0-46e3-8aa1-2b5c5233a31f/London_Boroughs.gpkg) and [London-wards-2018](https://data.london.gov.uk/download/statistical-gis-boundary-files-london/08d31995-dd27-423c-a987-57fe8e952990/London-wards-2018.zip) : This dataset is an extract from [Ordnance Survey](https://www.ordnancesurvey.co.uk/) Boundary-Line product which is a specialist 1:10 000 scale boundaries dataset.\n",
        "\n",
        ":::\n",
        "\n",
        "An inline citation: As discussed on @insideairbnb, there are many...\n",
        "\n",
        "A parenthetical citation: There are many ways to research Airbnb [see, for example, @insideairbnb]...\n",
        "\n",
        "## 2. Why did they collect it? ( 4 points; Answer due Week 7 )\n",
        "\n",
        ":::\n",
        "\n",
        "1.[\\*listings.csv](http://data.insideairbnb.com/united-kingdom/england/london/2023-09-06/data/listings.csv.gz) : Inside Airbnb is a mission driven project that provides data and advocacy about Airbnb's impact on residential communities. We work towards a vision where communities are empowered with data and information to understand, decide and control the role of renting residential homes to tourists.\n",
        "\n",
        "2.[\\*London_Boroughs.gpkg](https://data.london.gov.uk/download/london_boroughs/9502cdec-5df0-46e3-8aa1-2b5c5233a31f/London_Boroughs.gpkg) : With a long history and evolving from . The Ordnance Survey aims to help governments make smarter decisions that ensure our safety and security, they also show businesses how to gain a location data edge and we help everyone experience the benefits of the world outside. Under the [Public Sector Geospatial Agreement](https://www.ordnancesurvey.co.uk/customers/public-sector/public-sector-geospatial-agreement) (PSGA), Ordnance Survey (OS) provides Great Britain' national mapping services. OS creates, maintains and provides access to consistent, definitive and authoritative location data of Great Britain, aiming to help organisations to maximise the use, value and benefit of the data for the national interest and the public good. :::\n"
      ],
      "id": "bfb1f7c8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Data frame is {Airbnb_Listing.shape[0]:,} x {Airbnb_Listing.shape[1]:,}\")"
      ],
      "id": "1deeff40",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_hist_Listing = Airbnb_Listing.host_listings_count.plot.hist(bins=50)\n",
        "plot_hist_Listing.set_xlim([0, 500]);"
      ],
      "id": "e598c482",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. How was the data collected? ( 5 points; Answer due Week 8 )\n",
        "\n",
        "1.[\\*listings.csv](http://data.insideairbnb.com/united-kingdom/england/london/2023-09-06/data/listings.csv.gz) : Inside Airbnb collects its data primarily by scraping information from the Airbnb website. This process involves the following steps:\n",
        "\n",
        "**i.Web Scraping**: Inside Airbnb uses automated scripts to systematically browse and extract data from Airbnb's listings. These scripts navigate the website just like a human user would, but they do it much faster and on a larger scale.\n",
        "\n",
        "**ii.Data Extraction**: Information about each listing, such as location, price, availability, number of bedrooms, reviews, and host details, is extracted and compiled.\n",
        "\n",
        "**iii.Data Aggregation**: The collected data is then aggregated into a database. This database is organized to make it easier to analyze trends, patterns, and insights related to Airbnb's offerings in various cities and regions.\n",
        "\n",
        "**iv.Regular Updates**: The scraping process is repeated periodically to keep the database current, capturing new listings and updates to existing ones.\n",
        "\n",
        "**v.Public Accessibility**: The aggregated data is often made available to the public through the Inside Airbnb website, enabling researchers, policymakers, and the general public to analyze Airbnb's impact on housing markets and communities. It's important to note that web scraping practices, like those used by Inside Airbnb, may face legal and ethical considerations depending on the website's terms of service and regional laws regarding data privacy and usage.\n",
        "\n",
        "2.[\\*London_Boroughs.gpkg](https://data.london.gov.uk/download/london_boroughs/9502cdec-5df0-46e3-8aa1-2b5c5233a31f/London_Boroughs.gpkg) : \"Boundary-Line for England and Wales was initially digitised from Ordnance Survey's boundary record sheets at 1:10 000 scale (or, in some cases, at larger scales). The Government Statistical Service (GSS) codes are supplied by the Office for National Statistics and General Register Office for Scotland(GROS). GIS software provides the functionality to store, manage and manipulate this digital map data. The properties of the data make it suitable as a key base for users wishing to develop applications. BoundaryLine is also suitable for use within other digital mapping systems. It's coordinated on the National Grid which allows for the easy superimposition of other data.\n"
      ],
      "id": "f6c755ba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#print(Airbnb_Listing.info())\n",
        "print(Airbnb_Listing.columns)"
      ],
      "id": "342801d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. How does the method of collection impact the completeness and/or accuracy of its representation of the process it seeks to study, and what wider issues does this raise?\n",
        "\n",
        "::: duedate\n",
        "( 11 points; Answer due Week 9 ) ![gif](%22example.gif%22)\n",
        ":::\n"
      ],
      "id": "5a01d6e1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "###relating coding for PART4"
      ],
      "id": "0dac09f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. What ethical considerations does the use of this data raise?\n",
        "\n",
        "::: duedate\n",
        "( 18 points; Answer due {{< var assess.group-date >}} )\n",
        ":::\n"
      ],
      "id": "1dd105bc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "###relating coding for PART5"
      ],
      "id": "3a7bcb1e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. With reference to the data (*i.e.* using numbers, figures, maps, and descriptive statistics), what does an analysis of Hosts and Listing types suggest about the nature of Airbnb lets in London?\n",
        "\n",
        "文本特征如何被generalize和classified为Airbnb的推荐系统和branding系统提供 参考？\n",
        "\n",
        "1.为什么要看文本特征？\n",
        "\n",
        "有很多的研究从xxxx等方面，分析了Airbnb房源各方面的特征。包括价格、空间分布，房源类型等。但同时，不可忽略的一点是，在Airbnb网站平台的介绍中，\"文本描述\"作为其中重要的一环，影响着renters对房源的第一印象，同时对于促进一笔成功的rental交易起着重要作用，同时作为市场的正向反馈，房东host也会根据*政策的要求*调整着自己的description来迎合市场。\n",
        "\n",
        "因此，对于文本描述的分析既可以xxx，又可以。那么，在STL的大背景regulation下，如何通过分析房源的文本特征与房源的*签约成功率，综合income相关联*，来分析数据之间的联系relationship。并以这些relationship为指引来进行branding，帮助：\n",
        "\n",
        "1.  帮助房东获得更多的收益，\n",
        "2.  帮助Airbnb更高效的利用房源，\n",
        "3.  \"STL\"。\n",
        "\n",
        "How to maximize listings' utilize under 90-day STL regulation by their textual features/charactoristic?\n",
        "\n",
        "### 6.1 The definition of maximize income\n",
        "\n",
        "我们用\"minimum_nights\"列的数据乘以\"number_of_review\"xxxxx，乘以price。最后得到一个预估的总和'sum_income'.\n",
        "\n",
        "再结合各个borough不同的xxxx指标，来与sum_income综合比较之后得到一个综合指标。\n",
        "\n",
        "后续的所有文本特征分析，都以这个综合指标X来衡量。（综合指标与'是否超过90天'相结合）\n",
        "\n",
        "**(综合指标X分布图，与某些文献提到的middle-income neighbourhoods相匹配)**\n",
        "\n",
        "### 6.2 dataset中有哪些文本特征？\n",
        "\n",
        "1.  'description'：这一列的主要内容是房东对该房源的描述。那么，在各种各样的描述中，不同的房东会从哪些方面（主题topic）来对自己的房源进行描述（branding）？\n",
        "\n",
        "2.  'amenities'：这一列的主要内容是一些设施，场地，额外配置等。\n",
        "\n",
        "3.  以上这两个文本特征，在城市的空间分布中有怎样的集聚类型特征？是否在某些特定区域（社区），会有同质性房源的相似描述的高度集中分布？\n",
        "\n",
        "4.  这些文本特征如何与综合指标X来相关联？怎样的文本特征对提升综合指标X有着正向推动作用？\n",
        "\n",
        "#### 6.2.1 房东的房源描述有哪些共有主题（shared topic）？\n",
        "\n",
        "在所有的'description'描述中，通过LDA模型能够提取文本中的主题特征。\n",
        "\n",
        "在通过accurary值衡量不同数量topic的拟合程度之后，topic确认为16个。**（折线coherence value）**\n",
        "\n",
        "**16个词云图**（词云图中找出周边环境的特征信息）\n",
        "\n",
        "#### 6.2.2 amenities有哪些的空间分布特征？\n",
        "\n",
        "**向量散点图+底图散点分布**\n",
        "\n",
        "#### 6.2.3 怎样的ameinities对综合指标X有正向作用？\n",
        "\n",
        "**向量回归模型SVM分类**\n",
        "\n",
        "1.  同质性房源的空间分布（聚集与哪些社区？哪些区域？\n",
        "\n",
        "2.  现有房源描述的关键词有哪些？哪些文本特征有利于提高综合指标X？\n"
      ],
      "id": "5f49b08c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "###relating coding for PART6"
      ],
      "id": "2925793f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Drawing on your previous answers, and supporting your response with evidence (e.g. figures, maps, and statistical analysis/models), how *could* this data set be used to inform the regulation of Short-Term Lets (STL) in London?\n",
        "\n",
        "文本特征提取信息——————branding的导向（参考\n",
        "\n",
        "branding的导向—————— 正向和负向对STL的影响？\n",
        "\n",
        "Airbnb 可以参考branding导向做两件事：\n",
        "\n",
        "1.  更多的推荐那些有着更高*出租利润率*的房源。（单体收入更高，但是会导致部分房子）\n",
        "\n",
        "2.  更多的推荐那些*出租利润率*较低的房源，让整体的房屋入住率较为平均（时间上平均+空间上平均）\n",
        "\n",
        "正向：1.\n",
        "\n",
        "负向：1.\n",
        "\n",
        "::: duedate\n",
        "( 45 points; Answer due {{< var assess.group-date >}} )\n",
        ":::\n"
      ],
      "id": "5a4ef81e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "###relating coding for PART7"
      ],
      "id": "9cbee538",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sustainable Authorship Tools\n",
        "\n",
        "Your QMD file should automatically download your BibTeX file. We will then re-run the QMD file to generate the output successfully.\n",
        "\n",
        "Written in Markdown and generated from [Quarto](https://quarto.org/). Fonts used: [Spectral](https://fonts.google.com/specimen/Spectral) (mainfont), [Roboto](https://fonts.google.com/specimen/Roboto) ([sansfont]{style=\"font-family:Sans-Serif;\"}) and [JetBrains Mono](https://fonts.google.com/specimen/JetBrains%20Mono) (`monofont`).\n",
        "\n",
        "## References"
      ],
      "id": "24d444bf"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "jupytext": {
      "text_representation": {
        "extension": ".qmd",
        "format_name": "quarto",
        "format_version": "1.0",
        "jupytext_version": "1.15.2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}